\documentclass[10pt,oneside]{article}
\usepackage{amsmath} 
\usepackage{graphicx} 
\usepackage{subcaption} 
\usepackage{amsfonts}
\usepackage{amssymb} 

\newcommand{\tr}{\operatorname{trace}}
\newcommand{\vecm}{\operatorname{vec}}

\newcommand{\dotstar}{\operatorname{.*}}

%\usepackage{polyglossia}




\usepackage[
  backend=biber
]{biblatex}
\addbibresource{biblio.bib}


\usepackage[
  letterpaper,
  left=1cm,
  right=1cm,
  top=1.5cm,
  bottom=1.5cm
]{geometry}


\usepackage[
  final,
  unicode,
  colorlinks=true,
  citecolor=blue,
  linkcolor=blue,
  plainpages=false,
  urlcolor=blue,
  pdfpagelabels=true,
  pdfsubject={Cálculo},
  pdfauthor={José Doroteo Arango Arámbula},
  pdftitle={Tarea 1},
  pdfkeywords={UNAM, FES Acatlán, 2021-I}
]{hyperref}

\usepackage{booktabs}


\usepackage{algpseudocode}
\usepackage{algorithm} 
\floatname{algorithm}{Algoritmo}

\usepackage{enumitem}

\usepackage{lastpage}
\usepackage{fancyhdr}
\fancyhf{}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{MIT IAP January 2025} 
\fancyhead[C]{18.063 Matrix Calculus} 
\fancyhead[R]{Profs. Edelman and Johnson} 
\fancyfoot[R]{}
% https://tex.stackexchange.com/questions/227/how-can-i-add-page-of-on-my-document
\fancyfoot[C]{\thepage\ of \pageref*{LastPage}}
%\fancyfoot[C]{ of }
\fancyfoot[L]{} 
\renewcommand{\headrulewidth}{2pt} 
\renewcommand{\footrulewidth}{2pt}

\usepackage[newfloat=true]{minted} 

\author{} 
\title{Homework 1}

\date{\today}


\DeclareCaptionFormat{mitedFormat}{%
    \textbf{#1#2}#3}
\DeclareCaptionStyle{minetdStyle}{skip=0cm,width=.85\textwidth,justification=centering,
  font=footnotesize,singlelinecheck=off,format=mitedFormat,labelsep=space}
\newenvironment{mintedCode}{\captionsetup{type=listing,style=minetdStyle}}{}

\usepackage{dirtytalk} 

\SetupFloatingEnvironment{listing}{}

\usepackage[parfill]{parskip}

\usepackage{csquotes} 

\begin{document}
\maketitle
\thispagestyle{fancy} 

{\bf Please submit your HW on Canvas; include a PDF printout of any code and results, clearly labeled, e.g. from a Jupyter notebook.  For coding problems, we recommend using Julia, but you can use other languages if you wish. It is due Friday January 24th by 11:59pm EST.  }

\subsection*{Problem 1 (10 points)}

Start reading the draft course notes (linked from \url{https://github.com/mitmath/matrixcalc/}).   Find a place that you found confusing, and write a paragraph explaining the source of your confusion and (ideally) suggesting a possible improvement.

(Any other corrections/comments are welcome, too.)

\subsection*{Problem 2 (10 points)}

Later in the class we will look analytically at derivatives of eigenproblems.  Here you will begin to look at them empirically, with numerical experiments, using finite differences $\delta f = f(x+\delta x) - f(x) \approx f'(x)[\delta x]$.

    Let $f(A) = \lambda$ be a function that maps a real-symmetric matrix $A$ to one of its eigenvalues $\lambda$ (e.g.~the smallest one), satisfying $Av = \lambda v$ for some eigenvector $v$ normalized to $\| v \| = 1$, and suppose that the eigenvalue is \emph{not} a multiple eigenvalue. Demonstrate through numerical evidence  on random $4 \times 4$ matrices that $ \nabla \lambda = vv^T$.
    
(This result is known as the ``Hellmann--Feynman theorem'' in physics.)

\subsection*{Problem 3 (4+4+4+4 points)}

Find the derivatives $f'$ of the following functions.  If $f$ maps column vectors or matrices to scalars, give $\nabla f$ (so that $f'(x)[dx] = \langle \nabla f,  dx\rangle$ in the usual inner product). If $f$ maps column vectors to column vectors, give the Jacobian matrix.  Otherwise, simply write down $f'$ as a linear operation.

\begin{enumerate}

\item $f(x) = g.(x)$, denoting (in Julia notation) element-wise application of some scalar function $g$ (in terms of its scalar derivative $g'$), for $x \in \mathbb{R}^m$.

\item $f(A) = (A^T A)^{-1}$ where $A$ is an $m \times n$ matrix (with $m \ge n$ so that $A^T A$ is invertible for most $A$).

\item $f(x) = (I + x x^T)^{-1} x$ for $x \in \mathbb{R}^n$.

\item $f(A) = \tr(A^3)$ where $A$ is an $m \times m$ matrix.

\end{enumerate}
 
\subsection*{Problem 4 (5+5 points)}

Use the ``linear operator'' definition of Kronecker products, where $A \otimes B$ is interpreted as a linear operator on matrices given by $(A \otimes B)[C] = BCA^T$, to show

\begin{enumerate}

\item Associativity:
$$A \otimes (B \otimes C) =
(A \otimes B) \otimes C.$$

\item Mixed Products:
$$(A \otimes B)(C \otimes D) =
(AC \otimes BD).$$


 \end{enumerate}
\subsection*{Problem 5 (4+4+4 points)}

For this problem, recall that Newton's method finds a root $f(x)=0$ of a function $f(x)$ by iteratively improving a guess $x$ to $x \to x - f'(x)^{-1} f(x)$, assuming the derivative (or Jacobian) $f'$ is square and invertible.  It converges extremely rapidly if you start with a good enough initial guess.

If $A$ is an $n \times n$ matrix, an ordinary eigenvalue $\lambda$ solves $\det(A - \lambda I) = 0$.   More generally, you can find the roots $\det M(\lambda) = 0$ where $M(\lambda)$ is some arbitrary matrix-valued function of $\lambda$: this is called a \emph{nonlinear eigenvalue problem} and arises in lots of applications.  Newton's method (and variants thereof) can be a very good way to solve nonlinear eigenproblems!

\begin{enumerate}

\item If $M$ maps scalars $\lambda \in \mathbb{R}$ to $n\times n$ matrices $M(\lambda)$, explain why $M'(\lambda)$ (starting from the general definition of derivatives in class) is simply a matrix whose entries are the derivatives of each entry of $M$ with respect to $\lambda$.

\item If $f(\lambda) = \det M(\lambda)$, find the Newton step $f'(\lambda)^{-1} f(\lambda)$ in terms of $M'(\lambda)$.  (Simplify your answer: one term cancels nicely.)

\item Implement Newton's method to solve $\det M(\lambda) = 0$ for $M(\lambda) = A - \lambda I + \alpha \lambda \sin(\lambda) B$ with example $3\times 3$ matrices \texttt{A = [-2 -1 -7; -1 6 5; -7 5 6]}, \texttt{B = [7 -1 8; -1 7 -1; 8 -1 3]}, and $\alpha = 0.01$.  As your starting guess, use the largest eigenvalue of $A$ (i.e.~a solution for $\alpha = 0$), and find the resulting ``nonlinear eigenvalue'' of $M(\lambda)$ to at least~6 significant digits.  (It should require very few Newton steps!)

\end{enumerate}




 
\subsection*{Problem 6 (4+4+4+4 points)}

Let $f(A)$ be a function that maps $m \times m$ matrices to $m \times m$ matrices.  Recall that its derivative $f'(A)$ is a linear operator that maps any change $\delta A$ in $A$ to the corresponding change $\delta f = f(A+\delta A) - f(A) \approx f'(A)[\delta A]$, to first order in $\delta A$.

In this problem, you will study and prove a remarkable identity (Mathias, 1996): if $f(A)$ is sufficiently smooth,\footnote{The result is easiest to show when $f(A)$ has a Taylor series (is ``analytic''), and in fact you will do this below, but Higham (2008) shows that it remains true whenever $f$ is $2m-1$ times differentiable, or even just differentiable if $A$ is ``normal'' ($AA^T = A^T A$).} then for \emph{any} 
$\delta A$ (not necessarily small!) the following formula holds \emph{exactly}:
$$
f\left(\underbrace{\begin{bmatrix} A & \delta A \\ & A \end{bmatrix}}_M\right) = \begin{bmatrix} f(A) & f'(A)[\delta A] \\ & f(A) \end{bmatrix} \, .
$$
That is, one applies $f$ to a $2m \times 2m$ ``block upper-trianguar'' matrix $M$ (blank lower-left = zeros), and the desired derivative is in the upper-right $m \times m$ corner of the result $f(M)$.  (Note: please do your \emph{own} derivation here, don't just look it up.)

\begin{enumerate}

\item Check this identity numerically against a finite-difference approximation $f(A+\delta A) - f(A)$, which should match the exact $f'(A)[\delta A]$ to a few digits, for $f(A) = \exp(A)$ (the matrix exponential~$e^A$, computed by \texttt{exp(A)} in Julia, or \texttt{expm} in Scipy or Matlab), for a random $3 \times 3$ matrix \texttt{A = randn(3,3)} and a random small perturbation \texttt{dA = randn(3,3) * 1e-8}. Note that you can make the block matrix above in Julia by \texttt{using LinearAlgebra} followed by \texttt{M = [A dA; 0I A]}, and you can extract an upper-right corner by (\textit{e.g.}) \texttt{M[1:3,4:6]}.

It is also worth verifying (by a finite-difference check) that the derivative of the matrix exponential is \emph{not} simply multiplication by $e^A$ (on either the left or right or both): $(e^A)'[dA] \ne e^A \, dA$ or $dA \, e^A$ or $e^{A/2} \, dA \, e^{A/2}$, unlike the scalar case.

\item Prove the identity by explicit computation for the cases: $f(A) = I$, $f(A) = A$, $f(A) = A^2$, and $f(A) = A^3$.  (Two of these are trivial!  This is ``bargain-basement induction'': do a few small examples and see the pattern.)

\item Prove the identity for $f(A) = A^n$ for any $n \ge 0$ by induction: assume it works for $A^{n-1}$ and show using the product rule that it therefore must work for $A^n$.  (You already proved the trivial $n=0$ base case in the previous part.)

\emph{Remark:} 
Once it works for any $A^n$, it immediately follows that it works for any $f(A)$ described by a Taylor series, such as $\exp(A) = I + A + A^2/2 + A^3/6 + \cdots + A^n / n! + \cdots$, since such a function is just a linear combination of $A^n$ terms.

\item Prove the identity for $f(A) = A^{-1}$: since we know (from class) that $f'(A)[\delta A] = -A^{-1} \, \delta A \, A^{-1}$, plug this into the right-hand side of the formula above and show that it is the inverse of $M$ (multiply by $M$ and show you get $I$).\footnote{This is a special case of the famous ``Schur complement'' formula for the inverse of a $2 \times 2$ block matrix.}

\end{enumerate}

 
\end{document}
