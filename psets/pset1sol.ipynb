{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0edcb1f",
   "metadata": {},
   "source": [
    "# Matrix Calculus (18.063) Pset 1 Solutions\n",
    "\n",
    "This notebook contains computational solutions for problem set 1 of *18.063: Matrix Calculus* at MIT in IAP 2025.  See also the solutions PDF for mathematical derivations and analytical results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a700665b",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "We are asked to check that $\\nabla_A{\\lambda} = v v^T$, where $\\lambda$ is some eigenvalue of a real-symmetric matrix $A$ and $v$ is the corresponding unit-normalized eigenvector, using a random $4 \\times 4$ matrices.   \n",
    "\n",
    "We can generate a random real-symmetric matrix by $A = B + B^T$ where $B$ is an arbitrary real matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6ed99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Matrix{Float64}:\n",
       " -0.482936   -0.715913  -1.70091   -0.0236887\n",
       " -0.715913   -3.56332   -0.732205  -1.47105\n",
       " -1.70091    -0.732205   0.253464   0.182552\n",
       " -0.0236887  -1.47105    0.182552  -2.75639"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = randn(4,4)\n",
    "A = B + B'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f25d4",
   "metadata": {},
   "source": [
    "Let's also create a random small perturbation.  It turns out that the formula works even if the perturbation is not real-symmetric, in fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e103d588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Matrix{Float64}:\n",
       "  1.02237e-11   2.32632e-8   2.32533e-8   2.20845e-8\n",
       " -1.03699e-8   -1.88636e-9   1.04404e-8  -3.11713e-9\n",
       " -9.00341e-9   -9.42277e-9   8.60412e-9   9.62347e-9\n",
       " -3.92094e-9    1.24847e-8  -1.64921e-9   1.21897e-8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "δA = randn(4,4) * 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c941b0",
   "metadata": {},
   "source": [
    "It was sufficient to just check one eigenvalue, say the smallest one, but let's just check all of them.\n",
    "\n",
    "The `eigen(A)` function in the LinearAlgebra library will give us the eigenvalues and eigenvectors, and it automatically sorts the eigenvalues and normalizes the eigenvectors to unit magnitude so we don't have to worry about that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dacc62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  1.188114673311702e-8\n",
       "  2.027832124440465e-9\n",
       "  6.5526576387142654e-9\n",
       " -1.5439416412021956e-9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "λ, V = eigen(A)\n",
    "δλ = eigvals(A + δA) - λ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd82037",
   "metadata": {},
   "source": [
    "Now, let's try the formula, applied to each of the 4 eigenvectors.  Note that the columns of $V$ are the eigenvectors, so `λ[i]` corresponds to `V[:,i]`.  Also, note that `dot` in Julia gives the Frobenius inner product for two matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6582900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       "  1.1881160500284657e-8\n",
       "  2.0278345838592953e-9\n",
       "  6.552662002898275e-9\n",
       " -1.5439416493947632e-9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dλ = [ dot(V[:,i] * V[:,i]', δA) for i = 1:4 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e232c",
   "metadata": {},
   "source": [
    "Beautiful, they all match $\\delta \\lambda$ to a few significant digits (about as much as we can expect from a simple finite-difference approximation like this).\n",
    "\n",
    "You can run the whole thing a few times if you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9664c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm(δλ - dλ) / norm(dλ) = 1.3998932906429625e-6\n",
      "norm(δλ - dλ) / norm(dλ) = 6.384624638425199e-7\n",
      "norm(δλ - dλ) / norm(dλ) = 1.1994572440833222e-6\n",
      "norm(δλ - dλ) / norm(dλ) = 2.032401443943924e-6\n",
      "norm(δλ - dλ) / norm(dλ) = 6.35272235832111e-7\n",
      "norm(δλ - dλ) / norm(dλ) = 4.1804100802261764e-7\n",
      "norm(δλ - dλ) / norm(dλ) = 7.372242201918826e-7\n",
      "norm(δλ - dλ) / norm(dλ) = 9.663838924444233e-7\n",
      "norm(δλ - dλ) / norm(dλ) = 6.961791149971516e-7\n",
      "norm(δλ - dλ) / norm(dλ) = 2.535789068234015e-7\n"
     ]
    }
   ],
   "source": [
    "for _ = 1:10\n",
    "    B = randn(4,4)\n",
    "    A = B + B'\n",
    "    δA = randn(4,4) * 1e-8\n",
    "    λ, V = eigen(A)\n",
    "    δλ = eigvals(A + δA) - λ\n",
    "    dλ = [ dot(V[:,i] * V[:,i]', δA) for i = 1:4 ]\n",
    "    @show norm(δλ - dλ) / norm(dλ) # relative error\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d272b21",
   "metadata": {},
   "source": [
    "and we find that the relative error $\\Vert d\\lambda - \\delta\\lambda \\Vert / \\Vert d\\lambda \\Vert$ is always small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab6299f",
   "metadata": {},
   "source": [
    "## Problem 3 (optional numerical checks)\n",
    "\n",
    "You were *not* required to computationally validate your solutions on this problem, but it is always a good idea to do a quick finite-difference check, especially when the answer involved a bunch of algebra where you could easily make a mistake.\n",
    "\n",
    "We pick a random $x \\in \\mathbb{R}^5$ and $\\delta x \\in \\mathbb{R}^5$ on the order of $10^{-8}$ for use in all examples, and/or $A \\in \\mathbb{R}^{5 \\times 5}$ and $\\delta A \\in \\mathbb{R}^{5 \\times 5}$, and a function `relerr` to compute relative errors, which should be $\\ll 1$ compared to finite differences if our answers are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bcc633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra # for norm\n",
    "relerr(approx, exact) = norm(approx - exact) / norm(exact)\n",
    "\n",
    "x = randn(5)\n",
    "δx = randn(5) * 1e-8\n",
    "A = randn(5,5)\n",
    "δA = randn(5,5) * 1e-8;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f641180",
   "metadata": {},
   "source": [
    "### 3.1\n",
    "\n",
    "$f(x) = g.(x)$ gives $f' = \\mathrm{Diagonal}(g'.(x))$.  Check for $g(x) = \\sin(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48718a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.345900691824831e-9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_1(x) = sin.(x)\n",
    "f_1′(x) = Diagonal(cos.(x))\n",
    "relerr(f_1(x + δx) - f_1(x), f_1′(x) * δx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ae91b",
   "metadata": {},
   "source": [
    "### 3.2\n",
    "\n",
    "$f(x) = (A^T A)^{-1}$ gives\n",
    "$f'(A)[dA] = -f(A) (dA^T \\, A + A^T \\, dA) f(A)$\n",
    "Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "303f4e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.479231577342702e-8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_2(A) = (A'A)^-1\n",
    "f_2′(A) = dA -> -f_2(A) * (dA' * A + A' * dA) * f_2(A)\n",
    "relerr(f_2(A + δA) - f_2(A), f_2′(A)(δA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdffa6ea",
   "metadata": {},
   "source": [
    "### 3.3\n",
    "\n",
    "$f(x) = (I + xx^T)^{-1} x$ gives \n",
    "$$\n",
    "f'(x) = (1 - x^T f(x))  (I + xx^T)^{-1} - f(x) f(x)^T\n",
    "$$\n",
    "Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ef40ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3268069443429275e-8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_3(x) = (I + x*x') \\ x\n",
    "f_3′(x) = let f = f_3(x); (1 - x'f) * (I + x*x')^-1 - f*f'; end\n",
    "relerr(f_3(x + δx) - f_3(x), f_3′(x) * δx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c59557",
   "metadata": {},
   "source": [
    "### 3.4\n",
    "\n",
    "$f(A) = \\mathrm{trace}(A^3)$ gives $\\nabla f = (3A^2)^T$.  Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b7ee4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.795662972343922e-9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_4(A) = tr(A^3)\n",
    "∇f_4(A) = (3A^2)'\n",
    "relerr(f_4(A + δA) - f_4(A), ∇f_4(A) ⋅ δA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571635c3",
   "metadata": {},
   "source": [
    "(Note that `A ⋅ B` is equivalent to `dot(A, B)` in Julia, and for matrices this is the Frobenius inner product.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41deb2bb",
   "metadata": {},
   "source": [
    "**Hooray**, it all worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1f9420",
   "metadata": {},
   "source": [
    "## Problem 5.3\n",
    "\n",
    "In part 2, we showed that a Newton step for $f(\\lambda) = \\det(M(\\lambda))$ is \n",
    "$$\n",
    "\\lambda \\to \\lambda - f'(\\lambda)^{-1} f(\\lambda) = \\lambda - \\mathrm{trace}[M(\\lambda)^{-1} M'(\\lambda)]^{-1} \\, .\n",
    "$$\n",
    "\n",
    "Now, we are going to check it for $M(\\lambda) = A - \\lambda I + \\alpha \\lambda \\sin(\\lambda) B$ for $\\alpha = 0.01$ and given matrices $A, B$, using as a starting guess $\\lambda_0$ the largest eigenvalue of $A$.\n",
    "\n",
    "Note that the derivative of $M$ is simply $M'(\\lambda) = \\alpha (\\sin(\\lambda) + \\lambda \\cos(\\lambda)) B - I$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65814a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.310708435174291"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = [-2 -1 -7; -1 6 5; -7 5 6]\n",
    "B = [7 -1 8; -1 7 -1; 8 -1 3]\n",
    "α = 1//100 # exact rational coefficient\n",
    "\n",
    "M₅(λ) = A - λ*I + α*λ*sin(λ)*B\n",
    "M₅′(λ) = α * (sin(λ) + λ*cos(λ)) * B - I\n",
    "\n",
    "λ₀ = eigvals(A)[end] # largest eigenvalue of A as starting guess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96483b21",
   "metadata": {},
   "source": [
    "Now, let's do 5 Newton steps, printing out the change $\\Delta\\lambda$ on each step so we can watch it converge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f84675e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = 0.013878454139803088\n",
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = -6.179777913448486e-6\n",
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = -1.2943160456183902e-12\n",
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = 4.851259541298374e-16\n",
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = 4.851259541298374e-16\n",
      "λ = 13.324580709534885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.324580709534885"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "λ = λ₀\n",
    "for _ = 1:5\n",
    "    @show Δλ = -1 / tr(M₅(λ) \\ M₅′(λ))\n",
    "    λ += Δλ\n",
    "end\n",
    "@show λ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c31082",
   "metadata": {},
   "source": [
    "As is typical for Newton's method, the error roughly *squares* on each step.  Since our initial guess was correct to $\\approx 0.01$ (thanks to the fact that $\\alpha$ is small so that it is nearly a linear eigenproblem), it converges to machine precision in only 3 steps!\n",
    "\n",
    "The final answer of $\\boxed{\\lambda \\approx 13.324580709534885}$ should be accurate to more than 15 significant digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63286cba",
   "metadata": {},
   "source": [
    "In fact, if we want, we could get *many more* digits by switching to arbitrary-precision arithmetic, using Julia's `BigFloat` type, which defaults to about 77 significant digits.\n",
    "\n",
    "In `BigFloat` arithmetic, we have to be a bit careful that all of our parameters are entered exactly.  That's why we entered $\\alpha$ as `1//100` above, which is Julia syntax for the exact rational $\\frac{1}{100}$, rather than as the floating-point value `0.01` (which is actually rounded to a slightly nearby value).  Our initial guess can still be the same, however, since that is approximate anyway.\n",
    "\n",
    "Thanks to the rapid (\"quadratic\") convergence, it only takes 5–6 steps to converge to 77 digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4b71067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = 0.01387845413980278146924381478102036939592172873690338958398336900711028713973202\n",
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = -6.179777913283799906559965371941459950162437546405999559750023965330840318196745e-06\n",
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = -1.29483782619046423801795945492132904414631967410863748091816343685228771211928e-12\n",
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = -5.684469209316674137521208519556973673669745894000627686884323646805251349135944e-26\n",
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = -1.095567143853168221946500022463955277722520254619605286171673829733615056171145e-52\n",
      "Δλ = -1 / tr(M₅(λ) \\ M₅′(λ)) = -3.773682780296177136654839871911331258140476718388645796628924966406292865188501e-77\n",
      "λ = 13.32458070953488591297670726457428893073423073704312535878386385948794565820632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13.32458070953488591297670726457428893073423073704312535878386385948794565820632"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "λ = BigFloat(λ₀)\n",
    "for _ = 1:6\n",
    "    @show Δλ = -1 / tr(M₅(λ) \\ M₅′(λ))\n",
    "    λ += Δλ\n",
    "end\n",
    "@show λ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f09b91b",
   "metadata": {},
   "source": [
    "So, an even more exact answer, to 73 decimal places, is $\\lambda \\approx 13.3245807095348859129767072645742889307342307370431253587838638594879456582$.\n",
    "\n",
    "Comparing to our double-precision answer above, we see that we got 16 significant digits correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da72ce",
   "metadata": {},
   "source": [
    "## Problem 6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1969fd0f",
   "metadata": {},
   "source": [
    "Let's check the formula for the derivative of a matrix exponential with a random $3\\times 3$ matrix $A$ and a small perturbation $\\delta A$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd78f833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " -0.425224  2.18766     0.518162\n",
       "  1.32677   0.0196914   0.00593049\n",
       " -1.58095   1.28556    -0.891346"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "A = randn(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d7e9cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       "  2.00187e-9   9.20261e-9  -8.75115e-9\n",
       "  1.11933e-9  -3.24089e-9  -9.03447e-10\n",
       " -1.31247e-9   1.16987e-8   8.60381e-9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "δA = randn(3,3) * 1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afd4c2",
   "metadata": {},
   "source": [
    "First, we'll compute the finite difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f97c2904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       "  1.36821e-8  1.62146e-8  -4.71975e-9\n",
       "  5.72124e-9  4.1576e-9   -4.31738e-9\n",
       " -1.52379e-9  5.60998e-9   5.33695e-9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx = exp(A + δA) - exp(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683cc95c",
   "metadata": {},
   "source": [
    "Now, we'll use the analytical expression via $M = \\begin{pmatrix} A & \\delta A \\\\ & A \\end{pmatrix}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "796ffc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       "  1.36821e-8  1.62146e-8  -4.71975e-9\n",
       "  5.72124e-9  4.1576e-9   -4.31738e-9\n",
       " -1.52379e-9  5.60998e-9   5.33695e-9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [ A  δA\n",
    "     0I   A ]\n",
    "exact = exp(M)[1:3, 4:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e0b1a",
   "metadata": {},
   "source": [
    "By inspection, they match pretty well!  Let's be quantitative using the `relerr` function we defined for problem 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65cde689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.034023320947324e-8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relerr(approx, exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed6f80",
   "metadata": {},
   "source": [
    "They match to almost 8 digits, which is limited by the accuracy of the finite-difference approximation.  Success!"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
